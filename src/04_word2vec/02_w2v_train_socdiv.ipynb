{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px\" align=\"center\"> <b> Training Word2Vec on Biomedical Abstracts in PubMed </b> </div>\n",
    "\n",
    "<div style=\"font-size:18px\" align=\"center\"> <b> Brandon Kramer - University of Virginia's Biocomplexity Institute </b> </div>\n",
    "\n",
    "<br>\n",
    "\n",
    "This notebook borrows from several resources to train a Word2Vec model on a subset of the PubMed database taken from January 2021. Overall, I am interested in testing whether diversity and racial terms are becoming more closely related over time. To do this, I train the model on 1990-1995 data and then a random sample of 2015-2020 data. \n",
    "\n",
    "#### Import packages and ingest data \n",
    "\n",
    "Let's load all of our packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import Word\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing \n",
    "\n",
    "# set cores, grab stop words\n",
    "cores_available = multiprocessing.cpu_count() - 1\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching the Sample Sizes \n",
    "\n",
    "Since the 2010-2020 data is larger than the 1990-2000 data, we want to take a random sample of the later data to make the sample sizes the same for comparison later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk_pmid</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1366494</td>\n",
       "      <td>1990</td>\n",
       "      <td>although the discovery and transfer of technol...</td>\n",
       "      <td>although discovery transfer technology univers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1366495</td>\n",
       "      <td>1990</td>\n",
       "      <td>strategies for the development of diagnostic p...</td>\n",
       "      <td>strategy development diagnostic product acquir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1366496</td>\n",
       "      <td>1990</td>\n",
       "      <td>contemporary vaccines are relying increasingly...</td>\n",
       "      <td>contemporary vaccine relying increasingly mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1366497</td>\n",
       "      <td>1990</td>\n",
       "      <td>pseudomonas oleovorans can grow on linear alka...</td>\n",
       "      <td>pseudomonas oleovorans grow linear alkane alke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1366498</td>\n",
       "      <td>1990</td>\n",
       "      <td>there are many naturally occurring adhesive pr...</td>\n",
       "      <td>many naturally occurring adhesive protein pote...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fk_pmid  year                                           abstract  \\\n",
       "0  1366494  1990  although the discovery and transfer of technol...   \n",
       "1  1366495  1990  strategies for the development of diagnostic p...   \n",
       "2  1366496  1990  contemporary vaccines are relying increasingly...   \n",
       "3  1366497  1990  pseudomonas oleovorans can grow on linear alka...   \n",
       "4  1366498  1990  there are many naturally occurring adhesive pr...   \n",
       "\n",
       "                                      abstract_clean  \n",
       "0  although discovery transfer technology univers...  \n",
       "1  strategy development diagnostic product acquir...  \n",
       "2  contemporary vaccine relying increasingly mode...  \n",
       "3  pseudomonas oleovorans grow linear alkane alke...  \n",
       "4  many naturally occurring adhesive protein pote...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "pubmed_earlier = pd.read_csv(\"transformed_1990_2000_0821.csv\")\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract'].str.lower()\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].str.replace('-', ' ')\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if  not x.isdigit()))\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if not x in stop))\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].apply(lambda x:' '.join([Word(word).lemmatize() for word in x.split()]))\n",
    "pubmed_earlier.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the text data\n",
    "\n",
    "Convert all text to lower case, remove punctuation, numbers, dots, digits and stop words, and finally lemmatize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fk_pmid           1131646\n",
       "year              1131646\n",
       "abstract          1131646\n",
       "abstract_clean    1131646\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "pubmed_later = pd.read_csv(\"transformed_2010_2020_0821.csv\")\n",
    "pubmed_later = pubmed_later[pubmed_later['abstract'].notnull()]\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract'].str.lower()\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].str.replace('-', ' ')\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if not x.isdigit()))\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if not x in stop))\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].apply(lambda x:' '.join([Word(word).lemmatize() for word in x.split()]))\n",
    "pubmed_later.head()\n",
    "pubmed_later.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Word2Vec Models \n",
    "\n",
    "Now, let's train these Word2Vec models and save them as a binary file to visualize later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the earlier data \n",
    "earlier_list=[]\n",
    "for i in pubmed_earlier['abstract_clean']:\n",
    "    li = list(i.split(\" \"))\n",
    "    earlier_list.append(li)\n",
    "earlier_model = Word2Vec(earlier_list, min_count=5, vector_size=512, window=5, epochs=5, seed=123, workers=cores_available)\n",
    "\n",
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "earlier_model.save(\"word2vec_1990_2000_socdiv_0821.model\")\n",
    "earlier_model.save(\"word2vec_1990_2000_socdiv_0821.bin\")\n",
    "\n",
    "# run the model on the later data \n",
    "later_list=[]\n",
    "for i in pubmed_later['abstract_clean']:\n",
    "    li = list(i.split(\" \"))\n",
    "    later_list.append(li)\n",
    "later_model = Word2Vec(later_list, min_count=5, vector_size=512, window=5, epochs=5, seed=123, workers=cores_available)\n",
    "\n",
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "later_model.save(\"word2vec_2010_2020_socdiv_0821.model\")\n",
    "later_model.save(\"word2vec_2010_2020_socdiv_0821.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References \n",
    "\n",
    "[Guru 99's Tutorial on Word Embeddings](https://www.guru99.com/word-embedding-word2vec.html)\n",
    "\n",
    "[Stackoverflow Post on Lemmatizing in Pandas](https://stackoverflow.com/questions/47557563/lemmatization-of-all-pandas-cells)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brandon_env",
   "language": "python",
   "name": "brandon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
