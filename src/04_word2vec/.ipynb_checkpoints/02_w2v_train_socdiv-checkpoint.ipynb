{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px\" align=\"center\"> <b> Training Word2Vec on Biomedical Abstracts in PubMed </b> </div>\n",
    "\n",
    "<div style=\"font-size:18px\" align=\"center\"> <b> Brandon Kramer - University of Virginia's Biocomplexity Institute </b> </div>\n",
    "\n",
    "<br>\n",
    "\n",
    "This notebook borrows from several resources to train a Word2Vec model on a subset of the PubMed database taken from January 2021. Overall, I am interested in testing whether diversity and racial terms are becoming more closely related over time. To do this, I train the model on 1990-1995 data and then a random sample of 2015-2020 data. \n",
    "\n",
    "#### Import packages and ingest data \n",
    "\n",
    "Let's load all of our packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import Word\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing \n",
    "\n",
    "# set cores, grab stop words\n",
    "cores_available = multiprocessing.cpu_count() - 1\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "#pubmed_earlier = pd.read_csv(\"cleaned_1990_2000_0821.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching the Sample Sizes \n",
    "\n",
    "Since the 2010-2020 data is larger than the 1990-2000 data, we want to take a random sample of the later data to make the sample sizes the same for comparison later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk_pmid</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>human</th>\n",
       "      <th>nonhuman</th>\n",
       "      <th>abstract_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1655949</td>\n",
       "      <td>1991</td>\n",
       "      <td>advanced glycosylation endproducts (ages) are ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>advanced glycosylation endproducts age derived...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9283572</td>\n",
       "      <td>1997</td>\n",
       "      <td>we conducted a morphologic and anatomic study ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>conducted morphologic anatomic study alar cart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10559607</td>\n",
       "      <td>1999</td>\n",
       "      <td>many men with early stage prostate cancer suff...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>many men early stage prostate cancer suffer re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9117021</td>\n",
       "      <td>1997</td>\n",
       "      <td>we investigated whether exposure to a low leve...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>investigated whether exposure low level microg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8863225</td>\n",
       "      <td>1996</td>\n",
       "      <td>thirty-eight children (2 months to 26 yearsofa...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>thirty eight child month yearsofage underwent ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fk_pmid  year                                           abstract  human  \\\n",
       "0   1655949  1991  advanced glycosylation endproducts (ages) are ...      2   \n",
       "1   9283572  1997  we conducted a morphologic and anatomic study ...      0   \n",
       "2  10559607  1999  many men with early stage prostate cancer suff...      3   \n",
       "3   9117021  1997  we investigated whether exposure to a low leve...      2   \n",
       "4   8863225  1996  thirty-eight children (2 months to 26 yearsofa...      7   \n",
       "\n",
       "   nonhuman                                     abstract_clean  \n",
       "0         1  advanced glycosylation endproducts age derived...  \n",
       "1         0  conducted morphologic anatomic study alar cart...  \n",
       "2         0  many men early stage prostate cancer suffer re...  \n",
       "3         0  investigated whether exposure low level microg...  \n",
       "4         0  thirty eight child month yearsofage underwent ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "pubmed_earlier = pd.read_csv(\"cleaned_1990_2000_0821.csv\")\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract'].str.lower()\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].str.replace('-', ' ')\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if  not x.isdigit()))\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if not x in stop))\n",
    "pubmed_earlier['abstract_clean'] = pubmed_earlier['abstract_clean'].apply(lambda x:' '.join([Word(word).lemmatize() for word in x.split()]))\n",
    "pubmed_earlier.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the text data\n",
    "\n",
    "Convert all text to lower case, remove punctuation, numbers, dots, digits and stop words, and finally lemmatize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fk_pmid           1131646\n",
       "year              1131646\n",
       "abstract          1131646\n",
       "human             1131646\n",
       "nonhuman          1131646\n",
       "abstract_clean    1131646\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "pubmed_later = pd.read_csv(\"cleaned_2010_2020_0821.csv\")\n",
    "pubmed_later = pubmed_later[pubmed_later['abstract'].notnull()]\n",
    "#abstracts_to_sample = pubmed_earlier.count().year\n",
    "#pubmed_later = pubmed_later.sample(n=abstracts_to_sample, random_state=1)\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract'].str.lower()\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].str.replace('-', ' ')\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].str.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if not x.isdigit()))\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].apply(lambda x:' '.join(x for x in x.split() if not x in stop))\n",
    "pubmed_later['abstract_clean'] = pubmed_later['abstract_clean'].apply(lambda x:' '.join([Word(word).lemmatize() for word in x.split()]))\n",
    "pubmed_later.head()\n",
    "pubmed_later.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Word2Vec Models \n",
    "\n",
    "Now, let's train these Word2Vec models and save them as a binary file to visualize later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the earlier data \n",
    "earlier_list=[]\n",
    "for i in pubmed_earlier['abstract_clean']:\n",
    "    li = list(i.split(\" \"))\n",
    "    earlier_list.append(li)\n",
    "earlier_model = Word2Vec(earlier_list, min_count=5, vector_size=512, window=5, epochs=5, seed=123, workers=cores_available)\n",
    "\n",
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "earlier_model.save(\"word2vec_1990_2000_0821.model\")\n",
    "earlier_model.save(\"word2vec_1990_2000_0821.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model on the later data \n",
    "later_list=[]\n",
    "for i in pubmed_later['abstract_clean']:\n",
    "    li = list(i.split(\" \"))\n",
    "    later_list.append(li)\n",
    "later_model = Word2Vec(later_list, min_count=5, vector_size=512, window=5, epochs=5, seed=123, workers=cores_available)\n",
    "\n",
    "os.chdir(\"/sfs/qumulo/qhome/kb7hp/git/diversity/data/word_embeddings/\")\n",
    "later_model.save(\"word2vec_2010_2020_0821.model\")\n",
    "later_model.save(\"word2vec_2010_2020_0821.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References \n",
    "\n",
    "[Guru 99's Tutorial on Word Embeddings](https://www.guru99.com/word-embedding-word2vec.html)\n",
    "\n",
    "[Stackoverflow Post on Lemmatizing in Pandas](https://stackoverflow.com/questions/47557563/lemmatization-of-all-pandas-cells)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brandon_env",
   "language": "python",
   "name": "brandon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
